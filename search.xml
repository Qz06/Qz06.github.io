<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>ä»0å¼€å§‹çš„Transformer</title>
      <link href="/2026/02/23/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E7%9A%84Transformer/"/>
      <url>/2026/02/23/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E7%9A%84Transformer/</url>
      
        <content type="html"><![CDATA[<h1 id="åŸºäºpytorchï¼Œä»åº•å±‚å®ç°transformer"><a href="#åŸºäºpytorchï¼Œä»åº•å±‚å®ç°transformer" class="headerlink" title="åŸºäºpytorchï¼Œä»åº•å±‚å®ç°transformer"></a>åŸºäºpytorchï¼Œä»åº•å±‚å®ç°transformer</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> re</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">device=torch.device(<span class="string">&#x27;mps&#x27;</span>)</span><br></pre></td></tr></table></figure><p>è¯»å–æ•°æ®é›†ï¼Œè¿™é‡Œä½¿ç”¨â€time machineâ€</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">read_time_machine</span>():</span><br><span class="line">    <span class="comment"># è¿™é‡Œå‡è®¾ä½ å·²ç»æœ‰äº† txt æ–‡ä»¶ï¼Œæˆ–è€…ç›´æ¥ä»ç½‘ç»œä¸‹è½½</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;timemachine.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        lines = f.readlines()</span><br><span class="line">    <span class="keyword">return</span> [re.sub(<span class="string">&#x27;[^A-Za-z]+&#x27;</span>, <span class="string">&#x27; &#x27;</span>, line).strip().lower() <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br></pre></td></tr></table></figure><p>ä¸‹é¢å¼€å§‹å®ç°æ¨¡å‹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#å¤šå¤´æ³¨æ„åŠ›</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,num_hiddens,num_heads,dropout,bias=<span class="literal">False</span>,**kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.num_heads=num_heads</span><br><span class="line">        <span class="variable language_">self</span>.Wq=nn.LazyLinear(num_hiddens,bias=bias)</span><br><span class="line">        <span class="variable language_">self</span>.Wk=nn.LazyLinear(num_hiddens,bias=bias)</span><br><span class="line">        <span class="variable language_">self</span>.Wv=nn.LazyLinear(num_hiddens,bias=bias)</span><br><span class="line">        <span class="variable language_">self</span>.Wo=nn.LazyLinear(num_hiddens,bias=bias)</span><br><span class="line">        <span class="variable language_">self</span>.dropout=dropout</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">to_multihead_qkv</span>(<span class="params">self,X</span>):</span><br><span class="line">        <span class="comment">#X:(batch_size,steps,d)-&gt;(batch_size*num_heads,steps,d/num_heads)</span></span><br><span class="line">        X=X.reshape(X.shape[<span class="number">0</span>],X.shape[<span class="number">1</span>],<span class="variable language_">self</span>.num_heads,-<span class="number">1</span>)<span class="comment">#(bs,st,h,d/h)</span></span><br><span class="line">        X=X.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous()<span class="comment">#(bs,h,st,d/h)</span></span><br><span class="line">        X=X.reshape(-<span class="number">1</span>,X.shape[<span class="number">2</span>],X.shape[<span class="number">3</span>])</span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">to_single_output</span>(<span class="params">self,X</span>):</span><br><span class="line">        <span class="comment">#X:(batch_size*num_heads,steps,d/num_heads)-&gt;(batch_size,steps,d)</span></span><br><span class="line">        X=X.reshape(-<span class="number">1</span>,<span class="variable language_">self</span>.num_heads,X.shape[<span class="number">1</span>],X.shape[<span class="number">2</span>])<span class="comment">#(bs,h,st,d/h)</span></span><br><span class="line">        X=X.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous()<span class="comment">#(bs,st,h,d/h)</span></span><br><span class="line">        X=X.reshape(X.shape[<span class="number">0</span>],X.shape[<span class="number">1</span>],-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,Q,K,V,requires_mask</span>):</span><br><span class="line">        <span class="comment">#ä¸ºäº†è®¡ç®—é«˜æ•ˆï¼Œå…ˆä¹˜Wååˆ†å¤´</span></span><br><span class="line">        Q=<span class="variable language_">self</span>.to_multihead_qkv(<span class="variable language_">self</span>.Wq(Q))</span><br><span class="line">        K=<span class="variable language_">self</span>.to_multihead_qkv(<span class="variable language_">self</span>.Wk(K))</span><br><span class="line">        V=<span class="variable language_">self</span>.to_multihead_qkv(<span class="variable language_">self</span>.Wv(V))</span><br><span class="line"></span><br><span class="line">        d=Q.shape[-<span class="number">1</span>]</span><br><span class="line">        scores=torch.bmm(Q,K.transpose(<span class="number">1</span>,<span class="number">2</span>))/math.sqrt(d)<span class="comment">#scores:(batch_size*num_heads,queries,steps)</span></span><br><span class="line">        <span class="keyword">if</span> requires_mask:</span><br><span class="line">            <span class="keyword">if</span> scores.shape[<span class="number">1</span>]==scores.shape[<span class="number">2</span>]:</span><br><span class="line">                mask=torch.triu(torch.ones((scores.shape[<span class="number">1</span>],scores.shape[<span class="number">2</span>]),device=scores.device),diagonal=<span class="number">1</span>).<span class="built_in">bool</span>()</span><br><span class="line">                scores.masked_fill_(mask,-<span class="number">1e9</span>)</span><br><span class="line">        weights=nn.functional.softmax(scores,dim=-<span class="number">1</span>)</span><br><span class="line">        weights=nn.functional.dropout(weights,p=<span class="variable language_">self</span>.dropout,training=<span class="variable language_">self</span>.training)</span><br><span class="line">        Y=torch.bmm(weights,V)</span><br><span class="line">        Y_concat=<span class="variable language_">self</span>.to_single_output(Y)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.Wo(Y_concat)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ä½ç½®ç¼–ç </span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PositionalEncoding</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,num_hiddens,dropout,maxlen=<span class="number">1000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.dropout=nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.P=torch.zeros((<span class="number">1</span>,maxlen,num_hiddens))</span><br><span class="line">        position=torch.arange(maxlen,dtype=torch.float32).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, num_hiddens, <span class="number">2</span>, dtype=torch.float32) * -(math.log(<span class="number">10000.0</span>) / num_hiddens))</span><br><span class="line">        <span class="variable language_">self</span>.P[:, :, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        <span class="variable language_">self</span>.P[:, :, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,X</span>):</span><br><span class="line">        X=X+<span class="variable language_">self</span>.P[:,:X.shape[<span class="number">1</span>],:].to(X.device)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.dropout(X)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FFN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,num_input,num_hiddens,num_output,**kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        <span class="variable language_">self</span>.l1=nn.Linear(num_input,num_hiddens)</span><br><span class="line">        <span class="variable language_">self</span>.relu=nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.l2=nn.Linear(num_hiddens,num_output)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,X</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.l2(<span class="variable language_">self</span>.relu(<span class="variable language_">self</span>.l1(X)))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#æ®‹å·®è¿æ¥&amp;å±‚è§„èŒƒåŒ–</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AddLNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,LN_shape,dropout,**kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        <span class="variable language_">self</span>.dropout=nn.Dropout(dropout)</span><br><span class="line">        <span class="variable language_">self</span>.ln=nn.LayerNorm(LN_shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,Y,X</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.ln(X+<span class="variable language_">self</span>.dropout(Y))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ç¼–ç å™¨å—</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EncoderBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,num_hiddens,LN_shape,FFN_num_hiddens,num_heads,dropout,bias=<span class="literal">False</span>,**kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        <span class="variable language_">self</span>.attention=MultiHeadAttention(num_hiddens,num_heads,dropout,bias)</span><br><span class="line">        <span class="variable language_">self</span>.addnorm1=AddLNorm(LN_shape,dropout)</span><br><span class="line">        <span class="variable language_">self</span>.ffn=FFN(num_hiddens,FFN_num_hiddens,num_hiddens)</span><br><span class="line">        <span class="variable language_">self</span>.addnorm2=AddLNorm(LN_shape,dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,X</span>):</span><br><span class="line">        Y=<span class="variable language_">self</span>.addnorm1(<span class="variable language_">self</span>.attention(X,X,X,<span class="literal">False</span>),X)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.addnorm2(<span class="variable language_">self</span>.ffn(Y),Y)</span><br><span class="line">        </span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ç¼–ç å™¨</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,vocab_size,num_hiddens,LN_shape,FFN_num_hiddens,num_heads,dropout,num_layers,bias=<span class="literal">False</span>,**kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        <span class="variable language_">self</span>.num_hiddens=num_hiddens</span><br><span class="line">        <span class="variable language_">self</span>.embedding=nn.Embedding(vocab_size,num_hiddens)</span><br><span class="line">        <span class="variable language_">self</span>.pe=PositionalEncoding(num_hiddens,dropout)</span><br><span class="line">        <span class="variable language_">self</span>.blocks=nn.Sequential()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">            <span class="variable language_">self</span>.blocks.add_module(<span class="string">f&#x27;encoder_block_<span class="subst">&#123;i&#125;</span>&#x27;</span>,EncoderBlock(num_hiddens,LN_shape,FFN_num_hiddens,num_heads,dropout,bias=bias))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,X</span>):</span><br><span class="line">        X=<span class="variable language_">self</span>.pe(<span class="variable language_">self</span>.embedding(X)*math.sqrt(<span class="variable language_">self</span>.num_hiddens))</span><br><span class="line">        X=<span class="variable language_">self</span>.blocks(X)</span><br><span class="line">        <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#è§£ç å™¨å—</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DecoderBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,num_hiddens,LN_shape,FFN_num_hiddens,num_heads,dropout,idx,bias=<span class="literal">False</span>,**kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        <span class="variable language_">self</span>.idx=idx</span><br><span class="line">        <span class="variable language_">self</span>.selfattention=MultiHeadAttention(num_hiddens,num_heads,dropout,bias)</span><br><span class="line">        <span class="variable language_">self</span>.addnorm1=AddLNorm(LN_shape,dropout)</span><br><span class="line">        <span class="variable language_">self</span>.crossattention=MultiHeadAttention(num_hiddens,num_heads,dropout,bias)</span><br><span class="line">        <span class="variable language_">self</span>.addnorm2=AddLNorm(LN_shape,dropout)</span><br><span class="line">        <span class="variable language_">self</span>.ffn=FFN(num_hiddens,FFN_num_hiddens,num_hiddens)</span><br><span class="line">        <span class="variable language_">self</span>.addnorm3=AddLNorm(LN_shape,dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,X,state</span>):</span><br><span class="line">        enc_output,kv_cache=state[<span class="number">0</span>],state[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> kv_cache[<span class="variable language_">self</span>.idx] <span class="keyword">is</span> <span class="literal">None</span>:<span class="comment">#train or first token in prediction</span></span><br><span class="line">            k_and_v=X</span><br><span class="line">        <span class="keyword">else</span>:<span class="comment">#predict</span></span><br><span class="line">            k_and_v=torch.cat((kv_cache[<span class="variable language_">self</span>.idx],X),dim=<span class="number">1</span>)</span><br><span class="line">        kv_cache[<span class="variable language_">self</span>.idx]=k_and_v</span><br><span class="line">        X2=<span class="variable language_">self</span>.selfattention(X,k_and_v,k_and_v,<span class="literal">True</span>)</span><br><span class="line">        Y=<span class="variable language_">self</span>.addnorm1(X2,X)</span><br><span class="line">        Y2=<span class="variable language_">self</span>.crossattention(Y,enc_output,enc_output,<span class="literal">False</span>)</span><br><span class="line">        Z=<span class="variable language_">self</span>.addnorm2(Y2,Y)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.addnorm3(<span class="variable language_">self</span>.ffn(Z),Z),state</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#è§£ç å™¨</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,vocab_size,num_hiddens,LN_shape,FFN_num_hiddens,num_heads,dropout,num_layers,bias=<span class="literal">False</span>,**kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        <span class="variable language_">self</span>.num_hiddens=num_hiddens</span><br><span class="line">        <span class="variable language_">self</span>.num_layers=num_layers</span><br><span class="line">        <span class="variable language_">self</span>.embedding=nn.Embedding(vocab_size,num_hiddens)</span><br><span class="line">        <span class="variable language_">self</span>.pe=PositionalEncoding(num_hiddens,dropout)</span><br><span class="line">        <span class="variable language_">self</span>.blocks=nn.Sequential()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">            <span class="variable language_">self</span>.blocks.add_module(<span class="string">f&#x27;decoder_block_<span class="subst">&#123;i&#125;</span>&#x27;</span>,DecoderBlock(num_hiddens,LN_shape,FFN_num_hiddens,num_heads,dropout,idx=i,bias=bias))</span><br><span class="line">        <span class="variable language_">self</span>.dense=nn.Linear(num_hiddens,vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_state</span>(<span class="params">self,enc_output</span>):</span><br><span class="line">        <span class="keyword">return</span> [enc_output,[<span class="literal">None</span>]*<span class="variable language_">self</span>.num_layers]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,X,state</span>):</span><br><span class="line">        X=<span class="variable language_">self</span>.pe(<span class="variable language_">self</span>.embedding(X)*math.sqrt(<span class="variable language_">self</span>.num_hiddens))</span><br><span class="line">        <span class="keyword">for</span> block <span class="keyword">in</span> <span class="variable language_">self</span>.blocks:</span><br><span class="line">            X,state=block(X,state)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.dense(X),state</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyTransformerNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,encoder,decoder,**kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        <span class="variable language_">self</span>.encoder=encoder</span><br><span class="line">        <span class="variable language_">self</span>.decoder=decoder</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,enc_X,dec_X</span>):</span><br><span class="line">        enc_outputs=<span class="variable language_">self</span>.encoder(enc_X)</span><br><span class="line">        dec_state=<span class="variable language_">self</span>.decoder.init_state(enc_outputs)</span><br><span class="line">        Y_hat,dec_state=<span class="variable language_">self</span>.decoder(dec_X,dec_state)</span><br><span class="line">        <span class="keyword">return</span> Y_hat,dec_state</span><br></pre></td></tr></table></figure><p>æ¨¡å‹éƒ¨åˆ†ç»“æŸï¼Œä¸‹é¢æ˜¯æ•°æ®é¢„å¤„ç†ï¼Œè®­ç»ƒå’Œé¢„æµ‹éƒ¨åˆ†</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line"><span class="comment"># ====== 1. è¶…å‚æ•°  ======</span></span><br><span class="line">batch_size = <span class="number">128</span>      </span><br><span class="line">num_steps = <span class="number">40</span>        <span class="comment"># ä¸¥æ ¼å›ºå®šçš„åºåˆ—é•¿åº¦ (æ— å¡«å……)</span></span><br><span class="line">lr = <span class="number">0.001</span>            <span class="comment"># ä½¿ç”¨ Adam ä¼˜åŒ–å™¨ï¼Œ0.001 æ˜¯é»„é‡‘å¼€å±€</span></span><br><span class="line">epochs = <span class="number">20</span>           </span><br><span class="line"></span><br><span class="line"><span class="comment"># ====== 2. çº¯å‡€ç‰ˆè¯è¡¨ (åªéœ€ &lt;bos&gt; å’Œ *) ======</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RestoreVocab</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, tokens</span>):</span><br><span class="line">        <span class="comment"># åªéœ€è¦ &lt;bos&gt; å¼•å¯¼è§£ç ï¼Œä¸éœ€è¦ &lt;pad&gt;ï¼Œä¸éœ€è¦ &lt;eos&gt;</span></span><br><span class="line">        <span class="variable language_">self</span>.idx_to_token = [<span class="string">&#x27;&lt;bos&gt;&#x27;</span>, <span class="string">&#x27;*&#x27;</span>] </span><br><span class="line">        unique_tokens = <span class="built_in">list</span>(<span class="built_in">set</span>(tokens))</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;*&#x27;</span> <span class="keyword">in</span> unique_tokens: unique_tokens.remove(<span class="string">&#x27;*&#x27;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.idx_to_token.extend(unique_tokens)</span><br><span class="line">        <span class="variable language_">self</span>.token_to_idx = &#123;token: idx <span class="keyword">for</span> idx, token <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.idx_to_token)&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.idx_to_token)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, key</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(key, (<span class="built_in">list</span>, <span class="built_in">tuple</span>)):</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.token_to_idx.get(key, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> [<span class="variable language_">self</span>.__getitem__(token) <span class="keyword">for</span> token <span class="keyword">in</span> key]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ====== 3. æ•°æ®é›†æ„å»º ======</span></span><br><span class="line">lines = read_time_machine()</span><br><span class="line">corpus_chars = [char <span class="keyword">for</span> line <span class="keyword">in</span> lines <span class="keyword">for</span> char <span class="keyword">in</span> line]</span><br><span class="line">vocab = RestoreVocab(corpus_chars)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VowelRestoreDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, corpus_chars, num_steps, vocab</span>):</span><br><span class="line">        <span class="variable language_">self</span>.corpus = corpus_chars</span><br><span class="line">        <span class="variable language_">self</span>.num_steps = num_steps</span><br><span class="line">        <span class="variable language_">self</span>.vocab = vocab</span><br><span class="line">        <span class="variable language_">self</span>.vowels = <span class="built_in">set</span>(<span class="string">&#x27;aeiou&#x27;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.num_samples = <span class="built_in">len</span>(corpus_chars) - num_steps</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.num_samples</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="comment"># æˆªå–ç»å¯¹å®šé•¿çš„æ˜æ–‡ç‰‡æ®µ</span></span><br><span class="line">        chunk = <span class="variable language_">self</span>.corpus[idx : idx + <span class="variable language_">self</span>.num_steps]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Encoder è¾“å…¥: å°†å…ƒéŸ³æ›¿æ¢ä¸º * (é•¿åº¦ä¸å˜)</span></span><br><span class="line">        masked_chunk = [<span class="string">&#x27;*&#x27;</span> <span class="keyword">if</span> c <span class="keyword">in</span> <span class="variable language_">self</span>.vowels <span class="keyword">else</span> c <span class="keyword">for</span> c <span class="keyword">in</span> chunk]</span><br><span class="line">        enc_X = <span class="variable language_">self</span>.vocab[masked_chunk]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Decoder è¾“å…¥: &lt;bos&gt; å¼€å¤´ï¼Œå¹¶èˆå¼ƒåŸç‰‡æ®µæœ€åä¸€ä¸ªå­—ç¬¦ï¼Œç¡®ä¿æ€»é•¿åº¦ä»ä¸º num_steps</span></span><br><span class="line">        dec_X = [<span class="variable language_">self</span>.vocab[<span class="string">&#x27;&lt;bos&gt;&#x27;</span>]] + <span class="variable language_">self</span>.vocab[chunk[:-<span class="number">1</span>]]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Label: å°±æ˜¯æ˜æ–‡ç‰‡æ®µæœ¬èº«</span></span><br><span class="line">        Y = <span class="variable language_">self</span>.vocab[chunk]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> (torch.tensor(enc_X, dtype=torch.long),</span><br><span class="line">                torch.tensor(dec_X, dtype=torch.long),</span><br><span class="line">                torch.tensor(Y, dtype=torch.long))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¸¢å¼ƒæœ€åå‡‘ä¸é½ batch_size çš„æ•°æ®</span></span><br><span class="line">train_loader = DataLoader(VowelRestoreDataset(corpus_chars, num_steps, vocab), </span><br><span class="line">                          batch_size=batch_size, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å®ä¾‹åŒ–ä½ çš„ Transformer (ä½¿ç”¨ä½ ä¸Šæ–¹æ‰‹æ“çš„ä»£ç )</span></span><br><span class="line">num_hiddens, num_heads, num_layers, dropout = <span class="number">256</span>, <span class="number">8</span>, <span class="number">3</span>, <span class="number">0.1</span></span><br><span class="line">LN_shape = [num_hiddens]</span><br><span class="line">FFN_num_hiddens = num_hiddens * <span class="number">4</span> </span><br><span class="line"></span><br><span class="line">encoder = Encoder(<span class="built_in">len</span>(vocab), num_hiddens, LN_shape, FFN_num_hiddens, num_heads, dropout, num_layers)</span><br><span class="line">decoder = Decoder(<span class="built_in">len</span>(vocab), num_hiddens, LN_shape, FFN_num_hiddens, num_heads, dropout, num_layers)</span><br><span class="line">net = MyTransformerNet(encoder, decoder).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¼˜åŒ–å™¨ä¸æ™®é€šçš„äº¤å‰ç†µæŸå¤± (ä¸éœ€è¦å±è”½ä»»ä½•ä¸œè¥¿)</span></span><br><span class="line">optimizer = torch.optim.Adam(net.parameters(), lr=lr)</span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;ğŸš€ å¼€å§‹è¿›è¡Œ &#x27;å»å…ƒéŸ³å¤åŸ&#x27; è®­ç»ƒ...&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    net.train()</span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> enc_X, dec_X, Y <span class="keyword">in</span> train_loader:</span><br><span class="line">        enc_X, dec_X, Y = enc_X.to(device), dec_X.to(device), Y.to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># å‰å‘ä¼ æ’­</span></span><br><span class="line">        Y_hat, _ = net(enc_X, dec_X)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># è®¡ç®— Loss (ç›´æ¥å±•å¹³)</span></span><br><span class="line">        l = loss_fn(Y_hat.reshape(-<span class="number">1</span>, Y_hat.shape[-<span class="number">1</span>]), Y.reshape(-<span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        l.backward()</span><br><span class="line">        nn.utils.clip_grad_norm_(net.parameters(), max_norm=<span class="number">1.0</span>) <span class="comment"># è£å‰ªé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        total_loss += l.item()</span><br><span class="line">        </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;e + <span class="number">1</span>:02d&#125;</span>, Loss: <span class="subst">&#123;total_loss / <span class="built_in">len</span>(train_loader):<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>ğŸš€ å¼€å§‹åœ¨ M5 èŠ¯ç‰‡ä¸Šè¿›è¡Œ &#39;å»å…ƒéŸ³å¤åŸ&#39; è®­ç»ƒ...Epoch 01, Loss: 1.4954Epoch 02, Loss: 0.9292Epoch 03, Loss: 0.5886Epoch 04, Loss: 0.3895Epoch 05, Loss: 0.2511Epoch 06, Loss: 0.1716Epoch 07, Loss: 0.1105Epoch 08, Loss: 0.0815Epoch 09, Loss: 0.0703Epoch 10, Loss: 0.0623Epoch 11, Loss: 0.0574Epoch 12, Loss: 0.0531Epoch 13, Loss: 0.0500Epoch 14, Loss: 0.0473Epoch 15, Loss: 0.0449Epoch 16, Loss: 0.0423Epoch 17, Loss: 0.0411Epoch 18, Loss: 0.0393Epoch 19, Loss: 0.0383Epoch 20, Loss: 0.0370</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict_restore</span>(<span class="params">net, masked_text, vocab, device</span>):</span><br><span class="line">    net.<span class="built_in">eval</span>()</span><br><span class="line">    seq_len = <span class="built_in">len</span>(masked_text)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># ç¼–ç å¯†æ–‡</span></span><br><span class="line">    enc_tokens = vocab[<span class="built_in">list</span>(masked_text)]</span><br><span class="line">    enc_X = torch.tensor([enc_tokens], dtype=torch.long, device=device)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        enc_outputs = net.encoder(enc_X)</span><br><span class="line">        dec_state = net.decoder.init_state(enc_outputs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># æ”¾å…¥è§£ç å¼•å¯¼ç¬¦ &lt;bos&gt;</span></span><br><span class="line">        dec_X = torch.tensor([[vocab[<span class="string">&#x27;&lt;bos&gt;&#x27;</span>]]], dtype=torch.long, device=device)</span><br><span class="line">        outputs = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ä¸¥æ ¼æ‰§è¡Œä¸è¾“å…¥ç­‰é•¿çš„é¢„æµ‹æ­¥éª¤</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(seq_len):</span><br><span class="line">            Y_hat, dec_state = net.decoder(dec_X, dec_state)</span><br><span class="line">            next_token_idx = Y_hat[:, <span class="number">0</span>, :].argmax(dim=-<span class="number">1</span>).item()</span><br><span class="line">            </span><br><span class="line">            outputs.append(next_token_idx)</span><br><span class="line">            <span class="comment"># å–‚ç»™ä¸‹ä¸€æ­¥</span></span><br><span class="line">            dec_X = torch.tensor([[next_token_idx]], dtype=torch.long, device=device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;&quot;</span>.join([vocab.idx_to_token[i] <span class="keyword">for</span> i <span class="keyword">in</span> outputs])</span><br><span class="line"></span><br><span class="line"><span class="comment"># ================= è§è¯å¥‡è¿¹çš„æ—¶åˆ» =================</span></span><br><span class="line"><span class="comment"># è·‘å®Œ 20 è½®ä¹‹åè¿è¡Œè¿™è¡Œä»£ç ï¼š</span></span><br><span class="line">test_cases = [</span><br><span class="line">    <span class="string">&quot;th* t*m* tr*v*ll*r s*t d*wn&quot;</span>,    <span class="comment"># the time traveller sat down</span></span><br><span class="line">    <span class="string">&quot;h* m*d* * w*nd*rf*l d*sc*v*ry&quot;</span>,  <span class="comment"># he made a wonderful discovery</span></span><br><span class="line">    <span class="string">&quot;*t w*s * d*rk *nd st*rmy n*ght&quot;</span>  <span class="comment"># it was a dark and stormy night</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n==== ç ´è¯‘ç»“æœ ====&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> <span class="keyword">case</span> <span class="keyword">in</span> test_cases:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;è¾“å…¥ (å¯†æ–‡) : <span class="subst">&#123;<span class="keyword">case</span>&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;è¾“å‡º (è¿˜åŸ) : <span class="subst">&#123;predict_restore(net, <span class="keyword">case</span>, vocab, device)&#125;</span>\n&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>==== ç ´è¯‘ç»“æœ ====è¾“å…¥ (å¯†æ–‡) : th* t*m* tr*v*ll*r s*t d*wnè¾“å‡º (è¿˜åŸ) : the time trave traveller saè¾“å…¥ (å¯†æ–‡) : h* m*d* * w*nd*rf*l d*sc*v*ryè¾“å‡º (è¿˜åŸ) : he made i wonderful discoveryè¾“å…¥ (å¯†æ–‡) : *t w*s * d*rk *nd st*rmy n*ghtè¾“å‡º (è¿˜åŸ) : it was a a dark andark and sto</code></pre><p><strong>æ³¨ï¼šæ•°æ®å¤„ç†ï¼Œè®­ç»ƒï¼Œé¢„æµ‹éƒ¨åˆ†ä¸ºGeminiç”Ÿæˆï¼Œä»»åŠ¡ä¸ºå¡«è¡¥å¥å­ä¸­çš„å…ƒéŸ³ï¼ˆç”¨æ˜Ÿå·è¡¨ç¤ºï¼‰</strong></p><h2 id="åè®°"><a href="#åè®°" class="headerlink" title="åè®°"></a>åè®°</h2><p>è™½ç„¶Transformeråœ¨å¦‚ä»Šçš„æ·±åº¦å­¦ä¹ é¢†åŸŸæ˜¯å¦‚åŒâ€œHello Worldâ€ä¸€èˆ¬çš„å­˜åœ¨ï¼Œä½†ç»è¿‡ä»Šå¤©çš„å°è¯•ï¼Œå‘ç°å¦‚æœä¸è°ƒç”¨torchä¸­çš„ç»„ä»¶ï¼Œçº¯æ‰‹å†™ä¸€ä¸ªTransformeræ¨¡å‹è¿˜æ˜¯å…·æœ‰ç›¸å½“çš„éš¾åº¦çš„ï¼Œä»£ç ä¸­çš„å„ç§ç»†èŠ‚ï¼Œtensorå½¢çŠ¶ï¼Œå„ç±»æ–¹æ³•çš„å‚æ•°ï¼Œä¸åŒç±»ä¹‹é—´çš„è€¦åˆï¼Œéƒ½éœ€è¦å¤§é‡çš„æ€è€ƒä¸æ¢³ç†ã€‚ä½†æ˜¯ï¼Œå¦ä¸€æ–¹é¢ï¼Œè¿™ç§â€œé€ è½®å­â€çš„è¿‡ç¨‹ç¡®å®å¤§å¤§åŠ æ·±äº†æˆ‘å¯¹äºæ¨¡å‹çš„ç†è§£ã€‚ææ¸…æ¥šæ•´ä¸ªæ¨¡å‹åœ¨è®­ç»ƒå’Œé¢„æµ‹æ—¶æ•°æ®æµåŠ¨çš„é€šé“ï¼ŒæµåŠ¨æ–¹å¼ï¼Œç»è¿‡äº†å“ªäº›ç±»&#x2F;å‡½æ•°ï¼Œå½¢çŠ¶å‘ç”Ÿäº†æ€æ ·çš„æ”¹å˜ï¼Œå¯¹äºå½¢æˆå¯¹æ¨¡å‹çš„æ·±åˆ»ç†è§£æ˜¯å¤§æœ‰è£¨ç›Šçš„ã€‚ç”šè‡³å¯ä»¥è¯´ï¼Œäº†è§£æ¨¡å‹åŸç†åªå å¤ç°æ¨¡å‹çš„30%ï¼Œå‰©ä¸‹çš„70%éƒ½è—åœ¨å®ç°ç»†èŠ‚ä¸è®¾è®¡å“²å­¦ä¸­ã€‚<br>è¿™ä¸ªTransformeræ¨¡å‹çš„å‚æ•°é‡å¤§çº¦åªæœ‰5Mï¼Œä¹Ÿå°±æ˜¯0.005Bï¼Œä½†åœ¨æˆ‘çš„è®¾å¤‡ä¸Šè®­ç»ƒä»ç„¶éœ€è¦3min&#x2F;epochï¼Œçœ‹æ¥æ·±åº¦å­¦ä¹ çœŸæ˜¯ä¸€ä¸ªæåº¦è€—è´¹èµ„æºå’Œç®—åŠ›çš„é¢†åŸŸï¼Œå¦‚æœè¯´MLæ˜¯â€œæœ¯ä¸šæœ‰ä¸“æ”»â€ï¼Œâ€œç²¾å‡†å‡»ç ´â€ï¼Œé‚£DLå°±æ˜¯â€œä¸€æ‹›é²œåƒéå¤©â€ï¼Œæ˜¯â€œåŠ›å¤§ç –é£â€ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> æŠ€æœ¯ </category>
          
          <category> AI </category>
          
          <category> NLP </category>
          
          <category> Transformer </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Transformer </tag>
            
            <tag> Pytorch </tag>
            
            <tag> é€ è½®å­ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BlogGuide</title>
      <link href="/2025/02/23/BlogGuide/"/>
      <url>/2025/02/23/BlogGuide/</url>
      
        <content type="html"><![CDATA[<p>æœ¬æ–‡é‡‡ç”¨<strong>Hexo</strong>+<strong>Git</strong>+<strong>Nodejs</strong>+<strong>Github</strong>+<strong>Aliyun</strong>+<strong>Vercel</strong>æ–¹å¼æ­å»ºä¸ªäººåšå®¢ç½‘ç«™</p><hr><h1 id="ä¸€-å¿…å¤‡å·¥å…·çš„å®‰è£…"><a href="#ä¸€-å¿…å¤‡å·¥å…·çš„å®‰è£…" class="headerlink" title="ä¸€,å¿…å¤‡å·¥å…·çš„å®‰è£…"></a>ä¸€,å¿…å¤‡å·¥å…·çš„å®‰è£…</h1><h2 id="ä¸‹è½½Git-Nodejs-Hexo"><a href="#ä¸‹è½½Git-Nodejs-Hexo" class="headerlink" title="ä¸‹è½½Git,Nodejs,Hexo"></a>ä¸‹è½½Git,Nodejs,Hexo</h2><ol><li>å®˜ç½‘ä¸‹è½½<a href="https://git-scm.com/downloads">git</a>,<a href="https://nodejs.org/en/">nodejs</a>å¹¶å®‰è£…</li><li>æµ‹è¯•æ˜¯å¦ä¸‹è½½æˆåŠŸ:<br><em>æ‰“å¼€cmd,è¾“å…¥:</em></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br><span class="line">npm -vï¼ˆè¿™ä¸ªæ˜¯nodeé™„å¸¦çš„ï¼‰</span><br><span class="line">git -v</span><br></pre></td></tr></table></figure><p><em>å‡ºç°ç‰ˆæœ¬å·å³ä¸ºå®‰è£…æˆåŠŸ</em><br>3. ä¸‹è½½Hexo:<br><em>åœ¨cmdä¸­è¾“å…¥:</em></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-cli -g</span><br></pre></td></tr></table></figure><h2 id="gitä¸githubçš„è´¦æˆ·é…ç½®-å¦‚æœä½ å·²æœ‰gitå’Œgithubè´¦å·-è¯·å¿½ç•¥æ­¤æ­¥"><a href="#gitä¸githubçš„è´¦æˆ·é…ç½®-å¦‚æœä½ å·²æœ‰gitå’Œgithubè´¦å·-è¯·å¿½ç•¥æ­¤æ­¥" class="headerlink" title="gitä¸githubçš„è´¦æˆ·é…ç½®(å¦‚æœä½ å·²æœ‰gitå’Œgithubè´¦å·,è¯·å¿½ç•¥æ­¤æ­¥)"></a>gitä¸githubçš„è´¦æˆ·é…ç½®(å¦‚æœä½ å·²æœ‰gitå’Œgithubè´¦å·,è¯·å¿½ç•¥æ­¤æ­¥)</h2><ol><li>è¿›å…¥ä»»æ„æ–‡ä»¶å¤¹,å³é”®ç©ºç™½å¤„ç„¶åç‚¹å‡»Git Bash Here,è¾“å…¥:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.email &quot;ä½ çš„é‚®ç®±&quot;</span><br><span class="line">git config --global user.name &quot;ä½ çš„åå­—&quot;</span><br></pre></td></tr></table></figure><ol start="2"><li>è¿›å…¥<a href="https://github.com/">GitHubç½‘ç«™</a>,æ³¨å†Œä¸€ä¸ªè´¦å·</li></ol><hr><h1 id="äºŒ-åˆ›å»ºGitHubä»“åº“"><a href="#äºŒ-åˆ›å»ºGitHubä»“åº“" class="headerlink" title="äºŒ,åˆ›å»ºGitHubä»“åº“"></a>äºŒ,åˆ›å»ºGitHubä»“åº“</h1><ul><li>è¿›å…¥GitHubç½‘ç«™,ç‚¹å‡»Create a new repositoryè¿›å…¥æ–°å»ºä»“åº“é¡µé¢,ä»“åº“åè¾“å…¥ï¼š</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ç”¨æˆ·å.github.io</span><br></pre></td></tr></table></figure><ul><li>å‹¾é€‰ Public</li><li>å‹¾é€‰ Add a README file</li><li>æ‹‰åˆ°ä¸‹é¢ç‚¹å‡»createåˆ›å»º</li></ul><hr><h1 id="ä¸‰-ç”ŸæˆSSH-Keys"><a href="#ä¸‰-ç”ŸæˆSSH-Keys" class="headerlink" title="ä¸‰,ç”ŸæˆSSH Keys"></a>ä¸‰,ç”ŸæˆSSH Keys</h1><ol><li>è¿›å…¥ä»»æ„æ–‡ä»¶å¤¹ï¼Œå³é”®ç©ºç™½å¤„ç„¶åç‚¹Git bash here,è¾“å…¥:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;é‚®ä»¶åœ°å€&quot;</span><br></pre></td></tr></table></figure><ul><li>ç„¶åæ•²4æ¬¡EnterâŒ¨ï¸</li><li>ç„¶åè¿›å…¥C:\Users\ç”¨æˆ·åï¼Œåœ¨é‡Œé¢è¿›å…¥.sshæ–‡ä»¶</li><li>ç”¨è®°äº‹æœ¬æ‰“å¼€é‡Œé¢çš„id_rsa.pub,å…¨é€‰å¤åˆ¶é‡Œé¢çš„ä»£ç </li></ul><ol start="2"><li>åŒæ­¥è‡³GitHub:</li></ol><ul><li>æ‰“å¼€github</li><li>è¿›å…¥ç”¨æˆ·è®¾ç½®ï¼Œæ‰¾åˆ°SSH keys</li><li>æ–°å»ºSSH keysï¼Œåç§°éšæ„ï¼Œåœ¨ä¸‹é¢ç²˜è´´ä»£ç ï¼Œ</li><li>ç„¶ååˆ›å»º</li></ul><ol start="3"><li>æµ‹è¯•æ˜¯å¦æˆåŠŸ,åœ¨git bashä¸­è¾“å…¥:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure><p>(æ³¨æ„,å¦‚æœä½ ä½¿ç”¨äº†Watt Toolkitè¿™ç±»çš„åŠ é€Ÿå™¨è½¯ä»¶,åœ¨è¿™ä¸€æ­¥è¯·æš‚æ—¶å…³é—­å®ƒ)</p><ul><li>å›è½¦ï¼Œç„¶åå†è¾“å…¥yes</li></ul><hr><h1 id="å››-åœ¨æœ¬åœ°ç”Ÿæˆç½‘é¡µå†…å®¹"><a href="#å››-åœ¨æœ¬åœ°ç”Ÿæˆç½‘é¡µå†…å®¹" class="headerlink" title="å››,åœ¨æœ¬åœ°ç”Ÿæˆç½‘é¡µå†…å®¹"></a>å››,åœ¨æœ¬åœ°ç”Ÿæˆç½‘é¡µå†…å®¹</h1><ol><li>åœ¨å–œæ¬¢ä½ç½®æ–°å»ºæ–‡ä»¶Blogï¼Œç„¶åè¿›å…¥æ–‡ä»¶å¤¹,å³é”®ç©ºç™½å¤„ç„¶åç‚¹Git bash hereï¼Œè¾“å…¥:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo init</span><br></pre></td></tr></table></figure><ul><li>å¦‚æœâ€˜command not findâ€™ï¼Œå°±åœ¨å‰é¢åŠ ä¸Šnpxï¼Œå¦‚ï¼š<code>npx hexo init</code></li></ul><ol start="2"><li>ä¾æ¬¡è¾“å…¥ä»¥ä¸‹3æ¡:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo install</span><br><span class="line">hexo g</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure><p>ï¼ˆå¦‚æœä¸æˆåŠŸçš„è¯å°±é‡å¤ç›´åˆ°æˆåŠŸï¼Œå› ä¸ºå›½å†…ä¸githubè¿æ¥ä¸ç¨³å®šï¼‰</p><ul><li>ç°åœ¨å°±å¯ä»¥å¤åˆ¶ç”Ÿæˆçš„é“¾æ¥è¿›å…¥æµè§ˆå™¨çœ‹åˆ°æˆ‘ä»¬ç”Ÿæˆçš„æœ¬åœ°æœåŠ¡å™¨äº†</li><li>ç„¶åå›åˆ°å‘½ä»¤è¡Œï¼Œctrl+cå…³é—­</li></ul><hr><h1 id="äº”-ä¸Šçº¿ç½‘ç«™"><a href="#äº”-ä¸Šçº¿ç½‘ç«™" class="headerlink" title="äº”,ä¸Šçº¿ç½‘ç«™"></a>äº”,ä¸Šçº¿ç½‘ç«™</h1><ol><li>è¿›å…¥ä¹‹å‰çš„Blogæ–‡ä»¶å¤¹ï¼Œç”¨è®°äº‹æœ¬æ‰“å¼€_config.yml,æ‹‰åˆ°æœ€ä¸‹é¢å°†deployåé¢çš„å…¨åˆ æ‰ï¼Œå¤åˆ¶ç²˜è´´è¿™æ®µ:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">type: git</span><br><span class="line">repository: </span><br><span class="line">branch: main</span><br></pre></td></tr></table></figure><ul><li>æ³¨æ„ç¼©è¿›æ ¼å¼ï¼šæ¯è¡Œå‰é¢éƒ½æœ‰ä¸¤ä¸ªç©ºæ ¼ä¸è¦åˆ ï¼Œæ¯ä¸ªå†’å·åé¢éƒ½æœ‰ä¸ªç©ºæ ¼ä¹Ÿä¸è¦åˆ ï¼</li></ul><ol start="2"><li>å»githubä¹‹å‰ç”Ÿæˆçš„ä»“åº“é¡µé¢ï¼Œç‚¹codeï¼Œå¤åˆ¶httpsé“¾æ¥,å°†å…¶ç²˜è´´åˆ°æˆ‘ä»¬è®°äº‹æœ¬ä¸­çš„<code>repositoryï¼š</code>åé¢,ç„¶åä¿å­˜é€€å‡º</li><li>å›åˆ°åšå®¢æ–‡ä»¶å¤¹,git bash,å®‰è£…è‡ªåŠ¨éƒ¨ç½²å‘å¸ƒå·¥å…·:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure><ol start="4"><li>ç„¶ååœ¨Blogæ–‡ä»¶å¤¹å³é”®æ‰“å¼€git bashï¼Œä¾æ¬¡è¾“å…¥:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo gï¼ˆç”Ÿæˆï¼‰</span><br><span class="line">hexo dï¼ˆä¸Šä¼ ï¼‰</span><br></pre></td></tr></table></figure><p><em>g-generate  d-deploy</em>(<code>hexo d</code>å¦‚æœä¸æˆåŠŸ,è¯·æŒ‚åŠ é€Ÿå™¨)</p><ol><li>æ¥ä¸‹æ¥æˆ‘ä»¬å°±æˆåŠŸæŠŠæœ¬åœ°å†…å®¹ä¸Šä¼ åˆ°githubäº†,ä¸Šä¼ æˆåŠŸä»¥åï¼Œæˆ‘ä»¬å°±ç®—æ­å»ºå¥½äº†ï¼ä¸Šè‡ªå·±çš„ç½‘å€çœ‹çœ‹å§!ç½‘å€æ˜¯æˆ‘ä»¬ä¹‹å‰è®¾çš„ä»“åº“åï¼šç”¨æˆ·å.github.io</li></ol><hr><h1 id="å…­-ç½‘ç«™é…ç½®"><a href="#å…­-ç½‘ç«™é…ç½®" class="headerlink" title="å…­,ç½‘ç«™é…ç½®"></a>å…­,ç½‘ç«™é…ç½®</h1><p>æˆ‘ä»¬çš„åšå®¢æ ‡é¢˜è¿˜æ˜¯é»˜è®¤çš„hexoï¼Œæ•´ä¸ªé¡µé¢æ˜¯åˆå§‹é»˜è®¤çš„ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å¯¹å…¶è¿›è¡Œä¿®æ”¹<br>ç”¨è®°äº‹æœ¬æ‰“å¼€æˆ‘ä»¬blogæ–‡ä»¶å¤¹ä¸­çš„_config.ymlæ–‡ä»¶<br>å°†#Siteä¸‹é¢æŒ‰è‡ªå·±çš„éœ€æ±‚å¡«ä¸Š:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">## Site</span><br><span class="line">title: æ ‡é¢˜</span><br><span class="line">subtitle: å‰¯æ ‡é¢˜</span><br><span class="line">description: æè¿°</span><br><span class="line">keywords: å…³é”®è¯</span><br><span class="line">author: ç«™ä¸»</span><br><span class="line">language: è¯­è¨€ï¼ˆå¯ä»¥å¡«å†™zh-CNï¼‰</span><br><span class="line">timezone: æ—¶åŒºï¼ˆå¯ä»¥å¡«å†™Asia/Shanghaiï¼‰</span><br></pre></td></tr></table></figure><p><strong>æ³¨æ„:æ¯æ¬¡ä¿®æ”¹ç½‘é¡µåéƒ½è¦åœ¨git bashä¸­æ‰§è¡Œä¸€æ¬¡â€hexoä¸‰ä»¶å¥—â€,å³:</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo cl</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><hr><h1 id="ä¸ƒ-è´­ä¹°åŸŸå"><a href="#ä¸ƒ-è´­ä¹°åŸŸå" class="headerlink" title="ä¸ƒ,è´­ä¹°åŸŸå"></a>ä¸ƒ,è´­ä¹°åŸŸå</h1><p>è¿›å…¥<a href="www.aliyun.com">é˜¿é‡Œäº‘</a>,è´­ä¹°ä¸€ä¸ªå–œæ¬¢çš„åŸŸåå¹¶è®°ä½</p><hr><h1 id="å…«-æ¥å…¥æœåŠ¡å™¨"><a href="#å…«-æ¥å…¥æœåŠ¡å™¨" class="headerlink" title="å…«,æ¥å…¥æœåŠ¡å™¨"></a>å…«,æ¥å…¥æœåŠ¡å™¨</h1><h2 id="vercelåˆ›å»ºproject"><a href="#vercelåˆ›å»ºproject" class="headerlink" title="vercelåˆ›å»ºproject"></a>vercelåˆ›å»ºproject</h2><ol><li>æ‰“å¼€<a href="https://vercel.com/qz06s-projects">vercelç½‘ç«™</a>,è¿™æ˜¯ä¸€ä¸ªå‰ç«¯é¡¹ç›®éƒ¨ç½²å¹³å°,ç”¨ä½ çš„GitHubè´¦å·æ³¨å†Œä¸€ä¸ªæ–°è´¦å·</li><li>ç‚¹å‡»å³ä¸Šè§’çš„add newâ€“project,åœ¨Import Git Repositoryä¸­æ‰¾åˆ°ä½ çš„ç½‘ç«™ä»“åº“,ç‚¹importâ€“Deploy</li></ol><h2 id="DNSè§£æ"><a href="#DNSè§£æ" class="headerlink" title="DNSè§£æ"></a>DNSè§£æ</h2><ol><li>éƒ¨ç½²å®Œæˆå,ç‚¹å‡»è¿›å…¥ä½ çš„project,ç‚¹å‡»å³ä¸Šè§’çš„domainsâ€“add,å°†ä½ è´­ä¹°çš„åŸŸåå¡«è¿›å»,ç‚¹add domain,æ­¤æ—¶åœ¨domainsä¸­ä¼šæ–°å¢ä¸¤ä¸ªç½‘ç«™,è®°ä½ä»–ä»¬çš„ç±»å‹(ä¸€èˆ¬æ˜¯Aå’Œcname)å’Œipåœ°å€(å³value)</li><li>å†æ¬¡è¿›å…¥é˜¿é‡Œäº‘,åœ¨åŸŸååˆ—è¡¨é‡Œæ‰¾åˆ°ä½ çš„ç½‘ç«™åŸŸå,ç‚¹â€è§£æâ€â€“å¿«é€Ÿæ·»åŠ è§£æ:é€‰æ‹©åŒ¹é…çš„ç±»å‹(Aå³IPv4,CNAMEå³å¦å¤–çš„ç›®æ ‡åŸŸå)ä¸å¯¹åº”çš„ç½‘ç«™åŸŸå,å¡«å…¥å¯¹åº”çš„ipåœ°å€,ç‚¹â€ç¡®å®šâ€</li><li>æ­¤æ—¶å†å›åˆ°vercel,æ–°å¢çš„ä¸¤ä¸ªç½‘ç«™åº”è¯¥éƒ½æ˜¾ç¤ºæ­£å¸¸äº†,è¿™ä¸¤ä¸ªç½‘å€å³ä¸ºä½ çš„åšå®¢ç½‘ç«™çš„åœ°å€,å¯ä»¥ç›´æ¥è¿›å…¥äº†</li></ol>]]></content>
      
      
      <categories>
          
          <category> æŠ€æœ¯ </category>
          
          <category> webå¼€å‘ </category>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> Butterfly </tag>
            
            <tag> blog </tag>
            
            <tag> åšå®¢ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2025/02/22/hello-world/"/>
      <url>/2025/02/22/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
