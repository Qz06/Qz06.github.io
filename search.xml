<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>从1开始的LSTM</title>
      <link href="/2026/02/23/%E4%BB%8E1%E5%BC%80%E5%A7%8B%E7%9A%84LSTM/"/>
      <url>/2026/02/23/%E4%BB%8E1%E5%BC%80%E5%A7%8B%E7%9A%84LSTM/</url>
      
        <content type="html"><![CDATA[<p><em>为什么是“从1开始”？因为RNN的逻辑实在太绕，而且正逐渐被Transformer取代，所以我直接调用了nn.LSTM，重点在于数据集处理和训练，预测函数</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleRNNModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, num_hiddens</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.num_hiddens = num_hiddens</span><br><span class="line">        <span class="comment"># 1. Embedding 层：把字符 ID 转成稠密向量</span></span><br><span class="line">        <span class="variable language_">self</span>.embedding = nn.Embedding(vocab_size, num_hiddens)</span><br><span class="line">        <span class="comment"># 2. RNN 层：核心循环动力</span></span><br><span class="line">        <span class="variable language_">self</span>.rnn = nn.LSTM(num_hiddens, num_hiddens, batch_first=<span class="literal">True</span>,num_layers=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 3. 输出层：把隐藏状态映射回词表大小，预测下一个字符</span></span><br><span class="line">        <span class="variable language_">self</span>.linear = nn.Linear(num_hiddens, vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X, state</span>):</span><br><span class="line">        <span class="comment"># X 形状: (batch_size, num_steps)</span></span><br><span class="line">        X = <span class="variable language_">self</span>.embedding(X) </span><br><span class="line">        <span class="comment"># output 形状: (batch_size, num_steps, num_hiddens)</span></span><br><span class="line">        output, state = <span class="variable language_">self</span>.rnn(X, state)</span><br><span class="line">        <span class="comment"># 把时间步维度展平，一次性过线性层加速计算</span></span><br><span class="line">        <span class="comment"># y 形状: (batch_size * num_steps, vocab_size)</span></span><br><span class="line">        y = <span class="variable language_">self</span>.linear(output.reshape(-<span class="number">1</span>, output.shape[-<span class="number">1</span>]))</span><br><span class="line">        <span class="keyword">return</span> y, state</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">begin_state</span>(<span class="params">self, batch_size, device</span>):</span><br><span class="line">        <span class="comment"># 初始化隐藏状态 H 为 0</span></span><br><span class="line">        <span class="keyword">return</span> (torch.zeros((<span class="number">2</span>, batch_size, <span class="variable language_">self</span>.num_hiddens), device=device),</span><br><span class="line">                torch.zeros((<span class="number">2</span>, batch_size, <span class="variable language_">self</span>.num_hiddens), device=device))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">read_time_machine</span>():</span><br><span class="line">    <span class="comment"># 这里假设你已经有了 txt 文件，或者直接从网络下载</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;timemachine.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        lines = f.readlines()</span><br><span class="line">    <span class="keyword">return</span> [re.sub(<span class="string">&#x27;[^A-Za-z]+&#x27;</span>, <span class="string">&#x27; &#x27;</span>, line).strip().lower() <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Vocab</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,tokens</span>):</span><br><span class="line">        counter=collections.Counter(tokens)</span><br><span class="line">        <span class="variable language_">self</span>.idx_to_token=[<span class="string">&#x27;&lt;unk&gt;&#x27;</span>]+[token <span class="keyword">for</span> (token,freq) <span class="keyword">in</span> counter.items()]</span><br><span class="line">        <span class="variable language_">self</span>.token_to_idx=&#123;token:idx <span class="keyword">for</span> (idx,token) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.idx_to_token)&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.idx_to_token)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, key</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(key,(<span class="built_in">list</span>,<span class="built_in">tuple</span>)):</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.token_to_idx.get(key,<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> [<span class="variable language_">self</span>.__getitem__(token) <span class="keyword">for</span> token <span class="keyword">in</span> key]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lines=read_time_machine()</span><br><span class="line">tokens=[token <span class="keyword">for</span> line <span class="keyword">in</span> lines <span class="keyword">for</span> token <span class="keyword">in</span> line]</span><br><span class="line">vocab=Vocab(tokens)</span><br><span class="line">corpus=vocab[tokens]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset,DataLoader</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TMDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,corpus,num_steps</span>):</span><br><span class="line">        <span class="variable language_">self</span>.corpus=corpus</span><br><span class="line">        <span class="variable language_">self</span>.num_steps=num_steps</span><br><span class="line">        <span class="variable language_">self</span>.num_samples=<span class="built_in">len</span>(corpus)-num_steps</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.num_samples</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self,idx</span>):</span><br><span class="line">        X=torch.tensor(<span class="variable language_">self</span>.corpus[idx:idx+<span class="variable language_">self</span>.num_steps])</span><br><span class="line">        y=torch.tensor(<span class="variable language_">self</span>.corpus[idx+<span class="number">1</span>:idx+<span class="number">1</span>+<span class="variable language_">self</span>.num_steps])</span><br><span class="line">        <span class="keyword">return</span> X,y</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">batch_size=<span class="number">64</span></span><br><span class="line">num_steps=<span class="number">32</span></span><br><span class="line">lr=<span class="number">0.01</span></span><br><span class="line">epochs=<span class="number">20</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataset=TMDataset(corpus,num_steps)</span><br><span class="line"></span><br><span class="line">train_loader=DataLoader(dataset,batch_size,shuffle=<span class="literal">True</span>,drop_last=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">net=SimpleRNNModel(vocab_size=<span class="built_in">len</span>(vocab),num_hiddens=<span class="number">256</span>)</span><br><span class="line">loss=nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.1</span>, momentum=<span class="number">0.9</span>) </span><br><span class="line">scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)</span><br><span class="line">device=torch.device(<span class="string">&#x27;mps&#x27;</span>)</span><br><span class="line">net.to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    net.train()</span><br><span class="line">    tloss=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> X,y <span class="keyword">in</span> train_loader:</span><br><span class="line">        X,y=X.to(device),y.to(device)</span><br><span class="line">        state=net.begin_state(batch_size,device)</span><br><span class="line">        y_pred,_=net(X,state)</span><br><span class="line">        l=loss(y_pred,y.reshape(-<span class="number">1</span>).long())</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        l.backward()</span><br><span class="line">        nn.utils.clip_grad_norm_(net.parameters(),max_norm=<span class="number">1</span>)</span><br><span class="line">        optimizer.step()</span><br><span class="line">        tloss+=l.item()</span><br><span class="line"></span><br><span class="line">    scheduler.step()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;e + <span class="number">1</span>&#125;</span>, loss <span class="subst">&#123;tloss / <span class="built_in">len</span>(train_loader):<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>epoch 1, loss 1.6600epoch 2, loss 1.1736epoch 3, loss 0.9350epoch 4, loss 0.7585epoch 5, loss 0.6386epoch 6, loss 0.5594epoch 7, loss 0.5061epoch 8, loss 0.4689epoch 9, loss 0.4426epoch 10, loss 0.4229epoch 11, loss 0.4076epoch 12, loss 0.3953epoch 13, loss 0.3854epoch 14, loss 0.3770epoch 15, loss 0.3701epoch 16, loss 0.3644epoch 17, loss 0.3598epoch 18, loss 0.3562epoch 19, loss 0.3536epoch 20, loss 0.3520</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">prefix,num_preds,net,vocab,device</span>):</span><br><span class="line">    outputs=[]</span><br><span class="line">    net.<span class="built_in">eval</span>()</span><br><span class="line">    outputs.append(vocab[prefix[<span class="number">0</span>]])</span><br><span class="line">    state=net.begin_state(<span class="number">1</span>,device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_last_token</span>():</span><br><span class="line">        <span class="keyword">return</span> torch.tensor([outputs[-<span class="number">1</span>]],device=device,dtype=torch.long).reshape((<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#warmup</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(prefix)):</span><br><span class="line">        _,state=net(get_last_token(),state)</span><br><span class="line">        outputs.append(vocab[prefix[i]])</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#predict</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_preds):</span><br><span class="line">        y_hat,state=net(get_last_token(),state)</span><br><span class="line">        outputs.append(y_hat.argmax(dim=<span class="number">1</span>).item())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join([vocab.idx_to_token[i] <span class="keyword">for</span> i <span class="keyword">in</span> outputs])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict(<span class="string">&#x27;the&#x27;</span>,<span class="number">200</span>,net,vocab,device)</span><br></pre></td></tr></table></figure><pre><code>&#39;the sun grow larger and dullerin the westward sky and the life of the old earth ebb away atlast more than thirty million years hence the huge red hot dome ofthe sun had come to obscure nearly a tenth par&#39;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> AI </category>
          
          <category> NLP </category>
          
          <category> RNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> 造轮子 </tag>
            
            <tag> NLP </tag>
            
            <tag> LSTM </tag>
            
            <tag> RNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从0开始的ResNet</title>
      <link href="/2026/02/23/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E7%9A%84ResNet/"/>
      <url>/2026/02/23/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E7%9A%84ResNet/</url>
      
        <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">transform_train=transforms.Compose([</span><br><span class="line">    transforms.RandomCrop(<span class="number">32</span>,padding=<span class="number">4</span>),</span><br><span class="line">    transforms.RandomHorizontalFlip(),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((<span class="number">0.4914</span>, <span class="number">0.4822</span>, <span class="number">0.4465</span>), (<span class="number">0.2023</span>, <span class="number">0.1994</span>, <span class="number">0.2010</span>)),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">transform_test=transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((<span class="number">0.4914</span>, <span class="number">0.4822</span>, <span class="number">0.4465</span>), (<span class="number">0.2023</span>, <span class="number">0.1994</span>, <span class="number">0.2010</span>)),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">trainset=torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>,train=<span class="literal">True</span>,download=<span class="literal">True</span>,transform=transform_train)</span><br><span class="line">testset=torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>,train=<span class="literal">False</span>,download=<span class="literal">True</span>,transform=transform_test)</span><br><span class="line"></span><br><span class="line">trainloader=torch.utils.data.DataLoader(dataset=trainset,batch_size=<span class="number">128</span>,shuffle=<span class="literal">True</span>,num_workers=<span class="number">2</span>)</span><br><span class="line">testloader=torch.utils.data.DataLoader(dataset=trainset,batch_size=<span class="number">100</span>,shuffle=<span class="literal">False</span>,num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">device=torch.device(<span class="string">&#x27;mps&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>Files already downloaded and verifiedFiles already downloaded and verified</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Residual</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_channels,output_channels,strides=<span class="number">1</span>,change_channels=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1=nn.Conv2d(in_channels=input_channels,out_channels=output_channels,kernel_size=<span class="number">3</span>,stride=strides,padding=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.BN1=nn.BatchNorm2d(output_channels)</span><br><span class="line">        <span class="variable language_">self</span>.conv2=nn.Conv2d(in_channels=output_channels,out_channels=output_channels,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.BN2=nn.BatchNorm2d(output_channels)</span><br><span class="line">        <span class="variable language_">self</span>.conv3=nn.Conv2d(in_channels=input_channels,out_channels=output_channels,kernel_size=<span class="number">1</span>,stride=strides) <span class="keyword">if</span> change_channels <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,X</span>):</span><br><span class="line">        Y=<span class="variable language_">self</span>.BN2(<span class="variable language_">self</span>.conv2(nn.functional.relu(<span class="variable language_">self</span>.BN1(<span class="variable language_">self</span>.conv1(X)))))</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.conv3:</span><br><span class="line">            X=<span class="variable language_">self</span>.conv3(X)</span><br><span class="line">        <span class="keyword">return</span> nn.functional.relu(Y+X)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">b1=nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">3</span>,<span class="number">64</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">    nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">residual_block</span>(<span class="params">input_channels,output_channels,num_residuals,first_block=<span class="literal">False</span></span>):</span><br><span class="line">    modules=[]</span><br><span class="line">    <span class="keyword">if</span> first_block:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_residuals):</span><br><span class="line">            modules.append(Residual(output_channels,output_channels))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_residuals):</span><br><span class="line">            <span class="keyword">if</span> i==<span class="number">0</span>:</span><br><span class="line">                modules.append(Residual(input_channels,output_channels,<span class="number">2</span>,<span class="literal">True</span>))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                modules.append(Residual(output_channels,output_channels))</span><br><span class="line">    <span class="keyword">return</span> modules</span><br><span class="line"></span><br><span class="line">b2=nn.Sequential(*residual_block(<span class="number">64</span>,<span class="number">64</span>,<span class="number">2</span>,<span class="literal">True</span>))</span><br><span class="line">b3=nn.Sequential(*residual_block(<span class="number">64</span>,<span class="number">128</span>,<span class="number">2</span>))</span><br><span class="line">b4=nn.Sequential(*residual_block(<span class="number">128</span>,<span class="number">256</span>,<span class="number">2</span>))</span><br><span class="line">b5=nn.Sequential(*residual_block(<span class="number">256</span>,<span class="number">512</span>,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">b6=nn.Sequential(</span><br><span class="line">    nn.AdaptiveAvgPool2d((<span class="number">1</span>,<span class="number">1</span>)),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">512</span>,<span class="number">10</span>)</span><br><span class="line">                 )</span><br><span class="line"></span><br><span class="line">net=nn.Sequential(b1,b2,b3,b4,b5,b6)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置参数</span></span><br><span class="line">lr, epochs = <span class="number">0.05</span>, <span class="number">10</span></span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">5e-4</span>)</span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;mps&quot;</span> <span class="keyword">if</span> torch.backends.mps.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">net.to(device)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;训练设备: <span class="subst">&#123;device&#125;</span> | 初始学习率: <span class="subst">&#123;lr&#125;</span> | 总轮次: <span class="subst">&#123;epochs&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">60</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="comment"># --- 训练阶段 ---</span></span><br><span class="line">    net.train()</span><br><span class="line">    train_l_sum, train_acc_sum, n = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> trainloader:</span><br><span class="line">        X, y = X.to(device), y.to(device)</span><br><span class="line">        y_pred = net(X)</span><br><span class="line">        l = loss(y_pred, y)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        l.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            train_l_sum += l.item() * y.shape[<span class="number">0</span>]</span><br><span class="line">            train_acc_sum += (y_pred.argmax(dim=<span class="number">1</span>) == y).<span class="built_in">sum</span>().item()</span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># --- 测试阶段 (每个 epoch 跑完验证一次) ---</span></span><br><span class="line">    net.<span class="built_in">eval</span>()</span><br><span class="line">    test_acc_sum, test_n = <span class="number">0.0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> X_test, y_test <span class="keyword">in</span> testloader:</span><br><span class="line">            X_test, y_test = X_test.to(device), y_test.to(device)</span><br><span class="line">            y_test_pred = net(X_test)</span><br><span class="line">            test_acc_sum += (y_test_pred.argmax(dim=<span class="number">1</span>) == y_test).<span class="built_in">sum</span>().item()</span><br><span class="line">            test_n += y_test.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># --- 打印日志 ---</span></span><br><span class="line">    epoch_time = time.time() - start_time</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;e + <span class="number">1</span>:2d&#125;</span>: &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;Loss <span class="subst">&#123;train_l_sum/n:<span class="number">.4</span>f&#125;</span> | &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;Train Acc <span class="subst">&#123;train_acc_sum/n*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>% | &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;Test Acc <span class="subst">&#123;test_acc_sum/test_n*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>% | &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;Time <span class="subst">&#123;epoch_time:<span class="number">.1</span>f&#125;</span>s&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">60</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练结束！&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>训练设备: mps | 初始学习率: 0.05 | 总轮次: 10------------------------------------------------------------/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(Epoch  1: Loss 1.6245 | Train Acc 40.54% | Test Acc 48.14% | Time 110.8s/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(Epoch  2: Loss 1.1272 | Train Acc 59.75% | Test Acc 63.38% | Time 106.7s/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(Epoch  3: Loss 0.8511 | Train Acc 70.13% | Test Acc 72.90% | Time 105.8s/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(Epoch  4: Loss 0.6854 | Train Acc 76.21% | Test Acc 75.15% | Time 105.8s/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(Epoch  5: Loss 0.5899 | Train Acc 79.61% | Test Acc 79.46% | Time 105.8s/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(Epoch  6: Loss 0.5213 | Train Acc 82.09% | Test Acc 80.06% | Time 106.4s/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(Epoch  7: Loss 0.4784 | Train Acc 83.50% | Test Acc 81.98% | Time 106.8s/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(Epoch  8: Loss 0.4414 | Train Acc 84.85% | Test Acc 85.02% | Time 105.8s/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(Epoch  9: Loss 0.4096 | Train Acc 86.00% | Test Acc 85.49% | Time 105.7s/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: &#39;dlopen(/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib  Referenced from: &lt;0B7EB158-53DC-3403-8A49-22178CAB4612&gt; /opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/image.so  Reason: tried: &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/lib/python3.10/lib-dynload/../../libjpeg.9.dylib&#39; (no such file), &#39;/opt/anaconda3/envs/d2l/bin/../lib/libjpeg.9.dylib&#39; (no such file)&#39;If you don&#39;t plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?  warn(Epoch 10: Loss 0.3862 | Train Acc 86.83% | Test Acc 82.18% | Time 106.4s------------------------------------------------------------训练结束！</code></pre>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> AI </category>
          
          <category> CV </category>
          
          <category> CNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CV </tag>
            
            <tag> ResNet </tag>
            
            <tag> CNN </tag>
            
            <tag> PyTorch </tag>
            
            <tag> 造轮子 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从0开始的Transformer</title>
      <link href="/2026/02/23/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E7%9A%84Transformer/"/>
      <url>/2026/02/23/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E7%9A%84Transformer/</url>
      
        <content type="html"><![CDATA[<h1 id="基于pytorch，从底层实现transformer"><a href="#基于pytorch，从底层实现transformer" class="headerlink" title="基于pytorch，从底层实现transformer"></a>基于pytorch，从底层实现transformer</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> re</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">device=torch.device(<span class="string">&#x27;mps&#x27;</span>)</span><br></pre></td></tr></table></figure><p>读取数据集，这里使用”time machine”</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">read_time_machine</span>():</span><br><span class="line">    <span class="comment"># 这里假设你已经有了 txt 文件，或者直接从网络下载</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;timemachine.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        lines = f.readlines()</span><br><span class="line">    <span class="keyword">return</span> [re.sub(<span class="string">&#x27;[^A-Za-z]+&#x27;</span>, <span class="string">&#x27; &#x27;</span>, line).strip().lower() <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br></pre></td></tr></table></figure><p>下面开始实现模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#多头注意力</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,num_hiddens,num_heads,dropout,bias=<span class="literal">False</span>,**kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.num_heads=num_heads</span><br><span class="line">        <span class="variable language_">self</span>.Wq=nn.LazyLinear(num_hiddens,bias=bias)</span><br><span class="line">        <span class="variable language_">self</span>.Wk=nn.LazyLinear(num_hiddens,bias=bias)</span><br><span class="line">        <span class="variable language_">self</span>.Wv=nn.LazyLinear(num_hiddens,bias=bias)</span><br><span class="line">        <span class="variable language_">self</span>.Wo=nn.LazyLinear(num_hiddens,bias=bias)</span><br><span class="line">        <span class="variable language_">self</span>.dropout=dropout</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">to_multihead_qkv</span>(<span class="params">self,X</span>):</span><br><span class="line">        <span class="comment">#X:(batch_size,steps,d)-&gt;(batch_size*num_heads,steps,d/num_heads)</span></span><br><span class="line">        X=X.reshape(X.shape[<span class="number">0</span>],X.shape[<span class="number">1</span>],<span class="variable language_">self</span>.num_heads,-<span class="number">1</span>)<span class="comment">#(bs,st,h,d/h)</span></span><br><span class="line">        X=X.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous()<span class="comment">#(bs,h,st,d/h)</span></span><br><span class="line">        X=X.reshape(-<span class="number">1</span>,X.shape[<span class="number">2</span>],X.shape[<span class="number">3</span>])</span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">to_single_output</span>(<span class="params">self,X</span>):</span><br><span class="line">        <span class="comment">#X:(batch_size*num_heads,steps,d/num_heads)-&gt;(batch_size,steps,d)</span></span><br><span class="line">        X=X.reshape(-<span class="number">1</span>,<span class="variable language_">self</span>.num_heads,X.shape[<span class="number">1</span>],X.shape[<span class="number">2</span>])<span class="comment">#(bs,h,st,d/h)</span></span><br><span class="line">        X=X.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous()<span class="comment">#(bs,st,h,d/h)</span></span><br><span class="line">        X=X.reshape(X.shape[<span class="number">0</span>],X.shape[<span class="number">1</span>],-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,Q,K,V,requires_mask</span>):</span><br><span class="line">        <span class="comment">#为了计算高效，先乘W后分头</span></span><br><span class="line">        Q=<span class="variable language_">self</span>.to_multihead_qkv(<span class="variable language_">self</span>.Wq(Q))</span><br><span class="line">        K=<span class="variable language_">self</span>.to_multihead_qkv(<span class="variable language_">self</span>.Wk(K))</span><br><span class="line">        V=<span class="variable language_">self</span>.to_multihead_qkv(<span class="variable language_">self</span>.Wv(V))</span><br><span class="line"></span><br><span class="line">        d=Q.shape[-<span class="number">1</span>]</span><br><span class="line">        scores=torch.bmm(Q,K.transpose(<span class="number">1</span>,<span class="number">2</span>))/math.sqrt(d)<span class="comment">#scores:(batch_size*num_heads,queries,steps)</span></span><br><span class="line">        <span class="keyword">if</span> requires_mask:</span><br><span class="line">            <span class="keyword">if</span> scores.shape[<span class="number">1</span>]==scores.shape[<span class="number">2</span>]:</span><br><span class="line">                mask=torch.triu(torch.ones((scores.shape[<span class="number">1</span>],scores.shape[<span class="number">2</span>]),device=scores.device),diagonal=<span class="number">1</span>).<span class="built_in">bool</span>()</span><br><span class="line">                scores.masked_fill_(mask,-<span class="number">1e9</span>)</span><br><span class="line">        weights=nn.functional.softmax(scores,dim=-<span class="number">1</span>)</span><br><span class="line">        weights=nn.functional.dropout(weights,p=<span class="variable language_">self</span>.dropout,training=<span class="variable language_">self</span>.training)</span><br><span class="line">        Y=torch.bmm(weights,V)</span><br><span class="line">        Y_concat=<span class="variable language_">self</span>.to_single_output(Y)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.Wo(Y_concat)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#位置编码</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PositionalEncoding</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,num_hiddens,dropout,maxlen=<span class="number">1000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.dropout=nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.P=torch.zeros((<span class="number">1</span>,maxlen,num_hiddens))</span><br><span class="line">        position=torch.arange(maxlen,dtype=torch.float32).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, num_hiddens, <span class="number">2</span>, dtype=torch.float32) * -(math.log(<span class="number">10000.0</span>) / num_hiddens))</span><br><span class="line">        <span class="variable language_">self</span>.P[:, :, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        <span class="variable language_">self</span>.P[:, :, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,X</span>):</span><br><span class="line">        X=X+<span class="variable language_">self</span>.P[:,:X.shape[<span class="number">1</span>],:].to(X.device)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.dropout(X)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#基于位置的前馈网络</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FFN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,num_input,num_hiddens,num_output,**kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        <span class="variable language_">self</span>.l1=nn.Linear(num_input,num_hiddens)</span><br><span class="line">        <span class="variable language_">self</span>.relu=nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.l2=nn.Linear(num_hiddens,num_output)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,X</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.l2(<span class="variable language_">self</span>.relu(<span class="variable language_">self</span>.l1(X)))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#残差连接&amp;层规范化</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AddLNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,LN_shape,dropout,**kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        <span class="variable language_">self</span>.dropout=nn.Dropout(dropout)</span><br><span class="line">        <span class="variable language_">self</span>.ln=nn.LayerNorm(LN_shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,Y,X</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.ln(X+<span class="variable language_">self</span>.dropout(Y))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#编码器块</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EncoderBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,num_hiddens,LN_shape,FFN_num_hiddens,num_heads,dropout,bias=<span class="literal">False</span>,**kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        <span class="variable language_">self</span>.attention=MultiHeadAttention(num_hiddens,num_heads,dropout,bias)</span><br><span class="line">        <span class="variable language_">self</span>.addnorm1=AddLNorm(LN_shape,dropout)</span><br><span class="line">        <span class="variable language_">self</span>.ffn=FFN(num_hiddens,FFN_num_hiddens,num_hiddens)</span><br><span class="line">        <span class="variable language_">self</span>.addnorm2=AddLNorm(LN_shape,dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,X</span>):</span><br><span class="line">        Y=<span class="variable language_">self</span>.addnorm1(<span class="variable language_">self</span>.attention(X,X,X,<span class="literal">False</span>),X)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.addnorm2(<span class="variable language_">self</span>.ffn(Y),Y)</span><br><span class="line">        </span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#编码器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,vocab_size,num_hiddens,LN_shape,FFN_num_hiddens,num_heads,dropout,num_layers,bias=<span class="literal">False</span>,**kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        <span class="variable language_">self</span>.num_hiddens=num_hiddens</span><br><span class="line">        <span class="variable language_">self</span>.embedding=nn.Embedding(vocab_size,num_hiddens)</span><br><span class="line">        <span class="variable language_">self</span>.pe=PositionalEncoding(num_hiddens,dropout)</span><br><span class="line">        <span class="variable language_">self</span>.blocks=nn.Sequential()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">            <span class="variable language_">self</span>.blocks.add_module(<span class="string">f&#x27;encoder_block_<span class="subst">&#123;i&#125;</span>&#x27;</span>,EncoderBlock(num_hiddens,LN_shape,FFN_num_hiddens,num_heads,dropout,bias=bias))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,X</span>):</span><br><span class="line">        X=<span class="variable language_">self</span>.pe(<span class="variable language_">self</span>.embedding(X)*math.sqrt(<span class="variable language_">self</span>.num_hiddens))</span><br><span class="line">        X=<span class="variable language_">self</span>.blocks(X)</span><br><span class="line">        <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#解码器块</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DecoderBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,num_hiddens,LN_shape,FFN_num_hiddens,num_heads,dropout,idx,bias=<span class="literal">False</span>,**kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        <span class="variable language_">self</span>.idx=idx</span><br><span class="line">        <span class="variable language_">self</span>.selfattention=MultiHeadAttention(num_hiddens,num_heads,dropout,bias)</span><br><span class="line">        <span class="variable language_">self</span>.addnorm1=AddLNorm(LN_shape,dropout)</span><br><span class="line">        <span class="variable language_">self</span>.crossattention=MultiHeadAttention(num_hiddens,num_heads,dropout,bias)</span><br><span class="line">        <span class="variable language_">self</span>.addnorm2=AddLNorm(LN_shape,dropout)</span><br><span class="line">        <span class="variable language_">self</span>.ffn=FFN(num_hiddens,FFN_num_hiddens,num_hiddens)</span><br><span class="line">        <span class="variable language_">self</span>.addnorm3=AddLNorm(LN_shape,dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,X,state</span>):</span><br><span class="line">        enc_output,kv_cache=state[<span class="number">0</span>],state[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> kv_cache[<span class="variable language_">self</span>.idx] <span class="keyword">is</span> <span class="literal">None</span>:<span class="comment">#train or first token in prediction</span></span><br><span class="line">            k_and_v=X</span><br><span class="line">        <span class="keyword">else</span>:<span class="comment">#predict</span></span><br><span class="line">            k_and_v=torch.cat((kv_cache[<span class="variable language_">self</span>.idx],X),dim=<span class="number">1</span>)</span><br><span class="line">        kv_cache[<span class="variable language_">self</span>.idx]=k_and_v</span><br><span class="line">        X2=<span class="variable language_">self</span>.selfattention(X,k_and_v,k_and_v,<span class="literal">True</span>)</span><br><span class="line">        Y=<span class="variable language_">self</span>.addnorm1(X2,X)</span><br><span class="line">        Y2=<span class="variable language_">self</span>.crossattention(Y,enc_output,enc_output,<span class="literal">False</span>)</span><br><span class="line">        Z=<span class="variable language_">self</span>.addnorm2(Y2,Y)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.addnorm3(<span class="variable language_">self</span>.ffn(Z),Z),state</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#解码器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,vocab_size,num_hiddens,LN_shape,FFN_num_hiddens,num_heads,dropout,num_layers,bias=<span class="literal">False</span>,**kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        <span class="variable language_">self</span>.num_hiddens=num_hiddens</span><br><span class="line">        <span class="variable language_">self</span>.num_layers=num_layers</span><br><span class="line">        <span class="variable language_">self</span>.embedding=nn.Embedding(vocab_size,num_hiddens)</span><br><span class="line">        <span class="variable language_">self</span>.pe=PositionalEncoding(num_hiddens,dropout)</span><br><span class="line">        <span class="variable language_">self</span>.blocks=nn.Sequential()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">            <span class="variable language_">self</span>.blocks.add_module(<span class="string">f&#x27;decoder_block_<span class="subst">&#123;i&#125;</span>&#x27;</span>,DecoderBlock(num_hiddens,LN_shape,FFN_num_hiddens,num_heads,dropout,idx=i,bias=bias))</span><br><span class="line">        <span class="variable language_">self</span>.dense=nn.Linear(num_hiddens,vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_state</span>(<span class="params">self,enc_output</span>):</span><br><span class="line">        <span class="keyword">return</span> [enc_output,[<span class="literal">None</span>]*<span class="variable language_">self</span>.num_layers]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,X,state</span>):</span><br><span class="line">        X=<span class="variable language_">self</span>.pe(<span class="variable language_">self</span>.embedding(X)*math.sqrt(<span class="variable language_">self</span>.num_hiddens))</span><br><span class="line">        <span class="keyword">for</span> block <span class="keyword">in</span> <span class="variable language_">self</span>.blocks:</span><br><span class="line">            X,state=block(X,state)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.dense(X),state</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#编码器-解码器模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyTransformerNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,encoder,decoder,**kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        <span class="variable language_">self</span>.encoder=encoder</span><br><span class="line">        <span class="variable language_">self</span>.decoder=decoder</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,enc_X,dec_X</span>):</span><br><span class="line">        enc_outputs=<span class="variable language_">self</span>.encoder(enc_X)</span><br><span class="line">        dec_state=<span class="variable language_">self</span>.decoder.init_state(enc_outputs)</span><br><span class="line">        Y_hat,dec_state=<span class="variable language_">self</span>.decoder(dec_X,dec_state)</span><br><span class="line">        <span class="keyword">return</span> Y_hat,dec_state</span><br></pre></td></tr></table></figure><p>模型部分结束，下面是数据预处理，训练和预测部分</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line"><span class="comment"># ====== 1. 超参数  ======</span></span><br><span class="line">batch_size = <span class="number">128</span>      </span><br><span class="line">num_steps = <span class="number">40</span>        <span class="comment"># 严格固定的序列长度 (无填充)</span></span><br><span class="line">lr = <span class="number">0.001</span>            <span class="comment"># 使用 Adam 优化器，0.001 是黄金开局</span></span><br><span class="line">epochs = <span class="number">20</span>           </span><br><span class="line"></span><br><span class="line"><span class="comment"># ====== 2. 纯净版词表 (只需 &lt;bos&gt; 和 *) ======</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RestoreVocab</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, tokens</span>):</span><br><span class="line">        <span class="comment"># 只需要 &lt;bos&gt; 引导解码，不需要 &lt;pad&gt;，不需要 &lt;eos&gt;</span></span><br><span class="line">        <span class="variable language_">self</span>.idx_to_token = [<span class="string">&#x27;&lt;bos&gt;&#x27;</span>, <span class="string">&#x27;*&#x27;</span>] </span><br><span class="line">        unique_tokens = <span class="built_in">list</span>(<span class="built_in">set</span>(tokens))</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;*&#x27;</span> <span class="keyword">in</span> unique_tokens: unique_tokens.remove(<span class="string">&#x27;*&#x27;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.idx_to_token.extend(unique_tokens)</span><br><span class="line">        <span class="variable language_">self</span>.token_to_idx = &#123;token: idx <span class="keyword">for</span> idx, token <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.idx_to_token)&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.idx_to_token)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, key</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(key, (<span class="built_in">list</span>, <span class="built_in">tuple</span>)):</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.token_to_idx.get(key, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> [<span class="variable language_">self</span>.__getitem__(token) <span class="keyword">for</span> token <span class="keyword">in</span> key]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ====== 3. 数据集构建 ======</span></span><br><span class="line">lines = read_time_machine()</span><br><span class="line">corpus_chars = [char <span class="keyword">for</span> line <span class="keyword">in</span> lines <span class="keyword">for</span> char <span class="keyword">in</span> line]</span><br><span class="line">vocab = RestoreVocab(corpus_chars)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VowelRestoreDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, corpus_chars, num_steps, vocab</span>):</span><br><span class="line">        <span class="variable language_">self</span>.corpus = corpus_chars</span><br><span class="line">        <span class="variable language_">self</span>.num_steps = num_steps</span><br><span class="line">        <span class="variable language_">self</span>.vocab = vocab</span><br><span class="line">        <span class="variable language_">self</span>.vowels = <span class="built_in">set</span>(<span class="string">&#x27;aeiou&#x27;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.num_samples = <span class="built_in">len</span>(corpus_chars) - num_steps</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.num_samples</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="comment"># 截取绝对定长的明文片段</span></span><br><span class="line">        chunk = <span class="variable language_">self</span>.corpus[idx : idx + <span class="variable language_">self</span>.num_steps]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Encoder 输入: 将元音替换为 * (长度不变)</span></span><br><span class="line">        masked_chunk = [<span class="string">&#x27;*&#x27;</span> <span class="keyword">if</span> c <span class="keyword">in</span> <span class="variable language_">self</span>.vowels <span class="keyword">else</span> c <span class="keyword">for</span> c <span class="keyword">in</span> chunk]</span><br><span class="line">        enc_X = <span class="variable language_">self</span>.vocab[masked_chunk]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Decoder 输入: &lt;bos&gt; 开头，并舍弃原片段最后一个字符，确保总长度仍为 num_steps</span></span><br><span class="line">        dec_X = [<span class="variable language_">self</span>.vocab[<span class="string">&#x27;&lt;bos&gt;&#x27;</span>]] + <span class="variable language_">self</span>.vocab[chunk[:-<span class="number">1</span>]]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Label: 就是明文片段本身</span></span><br><span class="line">        Y = <span class="variable language_">self</span>.vocab[chunk]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> (torch.tensor(enc_X, dtype=torch.long),</span><br><span class="line">                torch.tensor(dec_X, dtype=torch.long),</span><br><span class="line">                torch.tensor(Y, dtype=torch.long))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 丢弃最后凑不齐 batch_size 的数据</span></span><br><span class="line">train_loader = DataLoader(VowelRestoreDataset(corpus_chars, num_steps, vocab), </span><br><span class="line">                          batch_size=batch_size, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实例化你的 Transformer (使用你上方手搓的代码)</span></span><br><span class="line">num_hiddens, num_heads, num_layers, dropout = <span class="number">256</span>, <span class="number">8</span>, <span class="number">3</span>, <span class="number">0.1</span></span><br><span class="line">LN_shape = [num_hiddens]</span><br><span class="line">FFN_num_hiddens = num_hiddens * <span class="number">4</span> </span><br><span class="line"></span><br><span class="line">encoder = Encoder(<span class="built_in">len</span>(vocab), num_hiddens, LN_shape, FFN_num_hiddens, num_heads, dropout, num_layers)</span><br><span class="line">decoder = Decoder(<span class="built_in">len</span>(vocab), num_hiddens, LN_shape, FFN_num_hiddens, num_heads, dropout, num_layers)</span><br><span class="line">net = MyTransformerNet(encoder, decoder).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 优化器与普通的交叉熵损失 (不需要屏蔽任何东西)</span></span><br><span class="line">optimizer = torch.optim.Adam(net.parameters(), lr=lr)</span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;🚀 开始进行 &#x27;去元音复原&#x27; 训练...&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    net.train()</span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> enc_X, dec_X, Y <span class="keyword">in</span> train_loader:</span><br><span class="line">        enc_X, dec_X, Y = enc_X.to(device), dec_X.to(device), Y.to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        Y_hat, _ = net(enc_X, dec_X)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算 Loss (直接展平)</span></span><br><span class="line">        l = loss_fn(Y_hat.reshape(-<span class="number">1</span>, Y_hat.shape[-<span class="number">1</span>]), Y.reshape(-<span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        l.backward()</span><br><span class="line">        nn.utils.clip_grad_norm_(net.parameters(), max_norm=<span class="number">1.0</span>) <span class="comment"># 裁剪防止梯度爆炸</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        total_loss += l.item()</span><br><span class="line">        </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;e + <span class="number">1</span>:02d&#125;</span>, Loss: <span class="subst">&#123;total_loss / <span class="built_in">len</span>(train_loader):<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>🚀 开始在 M5 芯片上进行 &#39;去元音复原&#39; 训练...Epoch 01, Loss: 1.4954Epoch 02, Loss: 0.9292Epoch 03, Loss: 0.5886Epoch 04, Loss: 0.3895Epoch 05, Loss: 0.2511Epoch 06, Loss: 0.1716Epoch 07, Loss: 0.1105Epoch 08, Loss: 0.0815Epoch 09, Loss: 0.0703Epoch 10, Loss: 0.0623Epoch 11, Loss: 0.0574Epoch 12, Loss: 0.0531Epoch 13, Loss: 0.0500Epoch 14, Loss: 0.0473Epoch 15, Loss: 0.0449Epoch 16, Loss: 0.0423Epoch 17, Loss: 0.0411Epoch 18, Loss: 0.0393Epoch 19, Loss: 0.0383Epoch 20, Loss: 0.0370</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict_restore</span>(<span class="params">net, masked_text, vocab, device</span>):</span><br><span class="line">    net.<span class="built_in">eval</span>()</span><br><span class="line">    seq_len = <span class="built_in">len</span>(masked_text)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 编码密文</span></span><br><span class="line">    enc_tokens = vocab[<span class="built_in">list</span>(masked_text)]</span><br><span class="line">    enc_X = torch.tensor([enc_tokens], dtype=torch.long, device=device)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        enc_outputs = net.encoder(enc_X)</span><br><span class="line">        dec_state = net.decoder.init_state(enc_outputs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 放入解码引导符 &lt;bos&gt;</span></span><br><span class="line">        dec_X = torch.tensor([[vocab[<span class="string">&#x27;&lt;bos&gt;&#x27;</span>]]], dtype=torch.long, device=device)</span><br><span class="line">        outputs = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 严格执行与输入等长的预测步骤</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(seq_len):</span><br><span class="line">            Y_hat, dec_state = net.decoder(dec_X, dec_state)</span><br><span class="line">            next_token_idx = Y_hat[:, <span class="number">0</span>, :].argmax(dim=-<span class="number">1</span>).item()</span><br><span class="line">            </span><br><span class="line">            outputs.append(next_token_idx)</span><br><span class="line">            <span class="comment"># 喂给下一步</span></span><br><span class="line">            dec_X = torch.tensor([[next_token_idx]], dtype=torch.long, device=device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;&quot;</span>.join([vocab.idx_to_token[i] <span class="keyword">for</span> i <span class="keyword">in</span> outputs])</span><br><span class="line"></span><br><span class="line"><span class="comment"># ================= 见证奇迹的时刻 =================</span></span><br><span class="line"><span class="comment"># 跑完 20 轮之后运行这行代码：</span></span><br><span class="line">test_cases = [</span><br><span class="line">    <span class="string">&quot;th* t*m* tr*v*ll*r s*t d*wn&quot;</span>,    <span class="comment"># the time traveller sat down</span></span><br><span class="line">    <span class="string">&quot;h* m*d* * w*nd*rf*l d*sc*v*ry&quot;</span>,  <span class="comment"># he made a wonderful discovery</span></span><br><span class="line">    <span class="string">&quot;*t w*s * d*rk *nd st*rmy n*ght&quot;</span>  <span class="comment"># it was a dark and stormy night</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n==== 破译结果 ====&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> <span class="keyword">case</span> <span class="keyword">in</span> test_cases:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;输入 (密文) : <span class="subst">&#123;<span class="keyword">case</span>&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;输出 (还原) : <span class="subst">&#123;predict_restore(net, <span class="keyword">case</span>, vocab, device)&#125;</span>\n&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>==== 破译结果 ====输入 (密文) : th* t*m* tr*v*ll*r s*t d*wn输出 (还原) : the time trave traveller sa输入 (密文) : h* m*d* * w*nd*rf*l d*sc*v*ry输出 (还原) : he made i wonderful discovery输入 (密文) : *t w*s * d*rk *nd st*rmy n*ght输出 (还原) : it was a a dark andark and sto</code></pre><p><strong>注：数据处理，训练，预测部分为Gemini生成，任务为填补句子中的元音（用星号表示）</strong></p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>虽然Transformer在如今的深度学习领域是如同“Hello World”一般的存在，但经过今天的尝试，发现如果不调用torch中的组件，纯手写一个Transformer模型还是具有相当的难度的，代码中的各种细节，tensor形状，各类方法的参数，不同类之间的耦合，都需要大量的思考与梳理。但是，另一方面，这种“造轮子”的过程确实大大加深了我对于模型的理解。搞清楚整个模型在训练和预测时数据流动的通道，流动方式，经过了哪些类&#x2F;函数，形状发生了怎样的改变，对于形成对模型的深刻理解是大有裨益的。甚至可以说，了解模型原理只占复现模型的30%，剩下的70%都藏在实现细节与设计哲学中。<br>这个Transformer模型的参数量大约只有5M，也就是0.005B，但在我的设备上训练仍然需要3min&#x2F;epoch，看来深度学习真是一个极度耗费资源和算力的领域，如果说ML是“术业有专攻”，“精准击破”，那DL就是“一招鲜吃遍天”，是“力大砖飞”。</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> AI </category>
          
          <category> NLP </category>
          
          <category> Transformer </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> 造轮子 </tag>
            
            <tag> NLP </tag>
            
            <tag> Transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BlogGuide</title>
      <link href="/2025/02/23/BlogGuide/"/>
      <url>/2025/02/23/BlogGuide/</url>
      
        <content type="html"><![CDATA[<p>本文采用<strong>Hexo</strong>+<strong>Git</strong>+<strong>Nodejs</strong>+<strong>Github</strong>+<strong>Aliyun</strong>+<strong>Vercel</strong>方式搭建个人博客网站</p><hr><h1 id="一-必备工具的安装"><a href="#一-必备工具的安装" class="headerlink" title="一,必备工具的安装"></a>一,必备工具的安装</h1><h2 id="下载Git-Nodejs-Hexo"><a href="#下载Git-Nodejs-Hexo" class="headerlink" title="下载Git,Nodejs,Hexo"></a>下载Git,Nodejs,Hexo</h2><ol><li>官网下载<a href="https://git-scm.com/downloads">git</a>,<a href="https://nodejs.org/en/">nodejs</a>并安装</li><li>测试是否下载成功:<br><em>打开cmd,输入:</em></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br><span class="line">npm -v（这个是node附带的）</span><br><span class="line">git -v</span><br></pre></td></tr></table></figure><p><em>出现版本号即为安装成功</em><br>3. 下载Hexo:<br><em>在cmd中输入:</em></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-cli -g</span><br></pre></td></tr></table></figure><h2 id="git与github的账户配置-如果你已有git和github账号-请忽略此步"><a href="#git与github的账户配置-如果你已有git和github账号-请忽略此步" class="headerlink" title="git与github的账户配置(如果你已有git和github账号,请忽略此步)"></a>git与github的账户配置(如果你已有git和github账号,请忽略此步)</h2><ol><li>进入任意文件夹,右键空白处然后点击Git Bash Here,输入:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.email &quot;你的邮箱&quot;</span><br><span class="line">git config --global user.name &quot;你的名字&quot;</span><br></pre></td></tr></table></figure><ol start="2"><li>进入<a href="https://github.com/">GitHub网站</a>,注册一个账号</li></ol><hr><h1 id="二-创建GitHub仓库"><a href="#二-创建GitHub仓库" class="headerlink" title="二,创建GitHub仓库"></a>二,创建GitHub仓库</h1><ul><li>进入GitHub网站,点击Create a new repository进入新建仓库页面,仓库名输入：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">用户名.github.io</span><br></pre></td></tr></table></figure><ul><li>勾选 Public</li><li>勾选 Add a README file</li><li>拉到下面点击create创建</li></ul><hr><h1 id="三-生成SSH-Keys"><a href="#三-生成SSH-Keys" class="headerlink" title="三,生成SSH Keys"></a>三,生成SSH Keys</h1><ol><li>进入任意文件夹，右键空白处然后点Git bash here,输入:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;邮件地址&quot;</span><br></pre></td></tr></table></figure><ul><li>然后敲4次Enter⌨️</li><li>然后进入C:\Users\用户名，在里面进入.ssh文件</li><li>用记事本打开里面的id_rsa.pub,全选复制里面的代码</li></ul><ol start="2"><li>同步至GitHub:</li></ol><ul><li>打开github</li><li>进入用户设置，找到SSH keys</li><li>新建SSH keys，名称随意，在下面粘贴代码，</li><li>然后创建</li></ul><ol start="3"><li>测试是否成功,在git bash中输入:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure><p>(注意,如果你使用了Watt Toolkit这类的加速器软件,在这一步请暂时关闭它)</p><ul><li>回车，然后再输入yes</li></ul><hr><h1 id="四-在本地生成网页内容"><a href="#四-在本地生成网页内容" class="headerlink" title="四,在本地生成网页内容"></a>四,在本地生成网页内容</h1><ol><li>在喜欢位置新建文件Blog，然后进入文件夹,右键空白处然后点Git bash here，输入:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo init</span><br></pre></td></tr></table></figure><ul><li>如果‘command not find’，就在前面加上npx，如：<code>npx hexo init</code></li></ul><ol start="2"><li>依次输入以下3条:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo install</span><br><span class="line">hexo g</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure><p>（如果不成功的话就重复直到成功，因为国内与github连接不稳定）</p><ul><li>现在就可以复制生成的链接进入浏览器看到我们生成的本地服务器了</li><li>然后回到命令行，ctrl+c关闭</li></ul><hr><h1 id="五-上线网站"><a href="#五-上线网站" class="headerlink" title="五,上线网站"></a>五,上线网站</h1><ol><li>进入之前的Blog文件夹，用记事本打开_config.yml,拉到最下面将deploy后面的全删掉，复制粘贴这段:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">type: git</span><br><span class="line">repository: </span><br><span class="line">branch: main</span><br></pre></td></tr></table></figure><ul><li>注意缩进格式：每行前面都有两个空格不要删，每个冒号后面都有个空格也不要删！</li></ul><ol start="2"><li>去github之前生成的仓库页面，点code，复制https链接,将其粘贴到我们记事本中的<code>repository：</code>后面,然后保存退出</li><li>回到博客文件夹,git bash,安装自动部署发布工具:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure><ol start="4"><li>然后在Blog文件夹右键打开git bash，依次输入:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g（生成）</span><br><span class="line">hexo d（上传）</span><br></pre></td></tr></table></figure><p><em>g-generate  d-deploy</em>(<code>hexo d</code>如果不成功,请挂加速器)</p><ol><li>接下来我们就成功把本地内容上传到github了,上传成功以后，我们就算搭建好了！上自己的网址看看吧!网址是我们之前设的仓库名：用户名.github.io</li></ol><hr><h1 id="六-网站配置"><a href="#六-网站配置" class="headerlink" title="六,网站配置"></a>六,网站配置</h1><p>我们的博客标题还是默认的hexo，整个页面是初始默认的，接下来我们对其进行修改<br>用记事本打开我们blog文件夹中的_config.yml文件<br>将#Site下面按自己的需求填上:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">## Site</span><br><span class="line">title: 标题</span><br><span class="line">subtitle: 副标题</span><br><span class="line">description: 描述</span><br><span class="line">keywords: 关键词</span><br><span class="line">author: 站主</span><br><span class="line">language: 语言（可以填写zh-CN）</span><br><span class="line">timezone: 时区（可以填写Asia/Shanghai）</span><br></pre></td></tr></table></figure><p><strong>注意:每次修改网页后都要在git bash中执行一次”hexo三件套”,即:</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo cl</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><hr><h1 id="七-购买域名"><a href="#七-购买域名" class="headerlink" title="七,购买域名"></a>七,购买域名</h1><p>进入<a href="www.aliyun.com">阿里云</a>,购买一个喜欢的域名并记住</p><hr><h1 id="八-接入服务器"><a href="#八-接入服务器" class="headerlink" title="八,接入服务器"></a>八,接入服务器</h1><h2 id="vercel创建project"><a href="#vercel创建project" class="headerlink" title="vercel创建project"></a>vercel创建project</h2><ol><li>打开<a href="https://vercel.com/qz06s-projects">vercel网站</a>,这是一个前端项目部署平台,用你的GitHub账号注册一个新账号</li><li>点击右上角的add new–project,在Import Git Repository中找到你的网站仓库,点import–Deploy</li></ol><h2 id="DNS解析"><a href="#DNS解析" class="headerlink" title="DNS解析"></a>DNS解析</h2><ol><li>部署完成后,点击进入你的project,点击右上角的domains–add,将你购买的域名填进去,点add domain,此时在domains中会新增两个网站,记住他们的类型(一般是A和cname)和ip地址(即value)</li><li>再次进入阿里云,在域名列表里找到你的网站域名,点”解析”–快速添加解析:选择匹配的类型(A即IPv4,CNAME即另外的目标域名)与对应的网站域名,填入对应的ip地址,点”确定”</li><li>此时再回到vercel,新增的两个网站应该都显示正常了,这两个网址即为你的博客网站的地址,可以直接进入了</li></ol>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> web开发 </category>
          
          <category> 博客 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> Butterfly </tag>
            
            <tag> blog </tag>
            
            <tag> 博客 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2025/02/22/hello-world/"/>
      <url>/2025/02/22/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
